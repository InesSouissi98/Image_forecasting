{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mQ4Hey2hmQZN"
      },
      "outputs": [],
      "source": [
        "from skimage import io, transform\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision \n",
        "from torchvision import transforms, utils\n",
        "import PIL\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import ImageNet\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.utils.data as data\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import os\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "import csv\n",
        "import torchvision \n",
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import time\n",
        "from  torch.autograd import Variable\n",
        "from torch.optim import lr_scheduler\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "from PIL import Image\n",
        "from sklearn.metrics import accuracy_score\n",
        "import random\n",
        "import cv2\n",
        "import torchvision.transforms as transforms\n",
        "from fastai.vision.all import show_image\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRhUOrtnmaQY",
        "outputId": "e164b5ae-de38-4d54-9ac8-a67704070059"
      },
      "outputs": [],
      "source": [
        "##We have a dataset of images that change over time (10 input images, 1 output image)\n",
        "!unzip \"/content/drive/MyDrive project dataset/train.zip\" -d \"/content/sample_data/train/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HYDQiPYXmeo-"
      },
      "outputs": [],
      "source": [
        "class LinearRegression(torch.nn.Module):\n",
        "\n",
        "   def __init__(self): \n",
        "      super(LinearRegression, self).__init__() \n",
        "      self.linear = torch.nn.Linear(128,128)\n",
        "      self.width=128\n",
        "      \n",
        "      self.w0 = nn.Conv2d(self.width, self.width, 1)\n",
        "      self.w1 = nn.Conv2d(self.width, self.width, 1)\n",
        "      self.w2 = nn.Conv2d(self.width, self.width, 1)\n",
        "      self.w3 = nn.Conv2d(self.width, self.width, 1)\n",
        "      self.bn0 = torch.nn.BatchNorm2d(self.width)\n",
        "      self.bn1 = torch.nn.BatchNorm2d(self.width)\n",
        "      self.bn2 = torch.nn.BatchNorm2d(self.width)\n",
        "      self.bn3 = torch.nn.BatchNorm2d(self.width)\n",
        "\n",
        "\n",
        "      #self.fc1 = nn.Linear(128, 128)\n",
        "      #self.fc2 = nn.Linear(128, 128)\n",
        "      \n",
        "   def forward(self, x): \n",
        "     predict_y = self.linear(x) \n",
        "     return predict_y "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LPOmwio5mgXd"
      },
      "outputs": [],
      "source": [
        "linear_model = LinearRegression()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZmoRwHBWmh8e"
      },
      "outputs": [],
      "source": [
        "define_criterion = torch.nn.MSELoss(size_average=None, reduce=None, reduction='mean')\n",
        "\n",
        "SGD_optimizer = torch.optim.SGD(linear_model.parameters(), lr=0.01,weight_decay=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XOBTGPv9mkGx",
        "outputId": "01716e0f-cb87-4ca2-c604-62135e356eda"
      },
      "outputs": [],
      "source": [
        "path=\"/content/sample_data/train/train\"\n",
        "sum_tensors=torch.ones(64, 128)\n",
        "\n",
        "nb_test_images=len([entry for entry in os.listdir(path) if os.path.isfile(os.path.join(path, entry))]) \n",
        "k=1\n",
        "#nb_test_images=5000\n",
        "for epoch in range(100):\n",
        "  sum_tensors=torch.ones(64,128)\n",
        " \n",
        "  k=1\n",
        "  while k<= nb_test_images:\n",
        "    #sum_tensors=torch.ones(3, 64, 128)\n",
        "    for i in range(10):\n",
        "      file_path=path+\"/image\"+str(k)+\".png\"\n",
        "    \n",
        "      \n",
        "    \n",
        "      image = cv2.imread(os.path.join(file_path))\n",
        "      image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "      #image.reshape(192,128)\n",
        "      image = Image.open(file_path)\n",
        "      \n",
        "      \n",
        "      #image = image.resize((64, 128))\n",
        "     \n",
        "      transform = transforms.Compose([\n",
        "      transforms.ToTensor()\n",
        "])\n",
        "\n",
        "      tensor = transform(image)\n",
        "      #tensor=image\n",
        "      sum_tensors=sum_tensors*tensor\n",
        "      k+=1\n",
        "\n",
        "    file_path=path+\"/image\"+str(k)+\".png\"\n",
        "    image1 = cv2.imread(os.path.join(file_path))\n",
        "    \n",
        "\n",
        "# Convert BGR image to RGB image\n",
        "    image1 = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)\n",
        "    image1 = Image.open(file_path)\n",
        "    #image1.reshape(3,64,128)\n",
        "    #image1 = image.resize((64, 128))\n",
        "  \n",
        "# Define a transform to convert\n",
        "# the image to torch tensor\n",
        "    transform = transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "    tensor_target = transform(image1)\n",
        "    predict_y = linear_model(sum_tensors) \n",
        "    loss = define_criterion(predict_y, tensor_target) \n",
        "  \n",
        "    SGD_optimizer.zero_grad() \n",
        "    loss.backward() \n",
        "    #torch.nn.utils.clip_grad_norm_(linear_model.parameters(), 5)\n",
        "    SGD_optimizer.step()\n",
        "    k+=1\n",
        "    sum_tensors=torch.ones(64,128)\n",
        "           \n",
        "      \n",
        "  print('epoch {}, loss function {}'.format(epoch, loss.item()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L3aKNHOqmtmn",
        "outputId": "abd5cb95-1d79-4d46-bdf9-552a3dd656dc"
      },
      "outputs": [],
      "source": [
        "!unzip \"/content/drive/MyDrive/fourier project dataset/test.zip\" -d \"/content/sample_data/test\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 577
        },
        "id": "VDpRGW6TmnhD",
        "outputId": "522ee231-37ea-439a-8bae-1e85c834aa57"
      },
      "outputs": [],
      "source": [
        "##test files\n",
        "\n",
        "sum_tensors=torch.ones(64, 128)\n",
        "path=\"/content/sample_data/test/test/\"\n",
        "#Number of images in test set\n",
        "nb_test_images=len([entry for entry in os.listdir(path) if os.path.isfile(os.path.join(path, entry))]) \n",
        "\n",
        "k=1\n",
        "while k<= nb_test_images:\n",
        "\n",
        "#for file in (os.listdir(path)):\n",
        "  for i in range(1,11):\n",
        "    \n",
        "  \n",
        "    file_path=path+\"/image\"+str(k)+\".png\"\n",
        "    \n",
        "      \n",
        "    \n",
        "    image = cv2.imread(os.path.join(file_path))\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    image = Image.open(file_path)\n",
        "      \n",
        "      #image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    #image = image.resize((64, 128))\n",
        "     \n",
        "    transform = transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "    tensor = transform(image)\n",
        "    sum_tensors=sum_tensors*tensor\n",
        "    k+=1\n",
        "\n",
        "  \n",
        "  prediction = linear_model(sum_tensors)\n",
        "  prediction.permute(1,2,0)\n",
        "  show_image(prediction,cmap='Greys_r')\n",
        "  #prediction=prediction.detach().numpy()\n",
        "  #plt.imshow(prediction.permute(1, 2, 0) )\n",
        "  k+=1\n",
        "  sum_tensors=torch.ones(64, 128)\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
